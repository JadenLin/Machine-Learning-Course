{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3 - Stock Movement Prediction\n",
    "\n",
    "作業檔案：\n",
    "- hw3.ipynb\n",
    "\n",
    "資料：\n",
    "https://www.sharecast.com/index/SP_500/prices/download\n",
    "\n",
    "- train.csv: S&P 500 訓練資料(2009-2017)\n",
    "- test.csv: S&P 500 測試資料(2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
      "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
      "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
      "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
      "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 6)\n",
      "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
      "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data_path = './train.csv'\n",
    "test_data_path = './test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2264, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(252, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "drop_col_names = ['Date'] # !--- or you can modify it to drop the columns you don't want ---!\n",
    "\n",
    "train_df.drop(columns=drop_col_names, inplace=True)\n",
    "test_df.drop(columns=drop_col_names, inplace=True)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(train_df.head())\n",
    "print(test_df.shape)\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "0      902.99       931.80      934.73     899.35  4048270080   \n",
      "1      929.17       927.45      936.63     919.53  5413910016   \n",
      "2      931.17       934.70      943.85     927.28  5392620032   \n",
      "3      927.45       906.65      927.45     902.37  4704940032   \n",
      "4      905.73       909.73      910.00     896.81  4991549952   \n",
      "\n",
      "   Tomorrow Movement  \n",
      "0                0.0  \n",
      "1                1.0  \n",
      "2                0.0  \n",
      "3                1.0  \n",
      "4                0.0  \n",
      "      Open Price  Close Price  High Price  Low Price      Volume  \\\n",
      "2259     2684.22      2683.34     2685.35    2678.13  1383888512   \n",
      "2260     2679.09      2680.50     2682.74    2677.96  1103808384   \n",
      "2261     2682.10      2682.62     2685.64    2678.91  1149108352   \n",
      "2262     2686.10      2687.54     2687.66    2682.69  1126089856   \n",
      "2263     2689.15      2673.61     2692.12    2673.61  1332374016   \n",
      "\n",
      "      Tomorrow Movement  \n",
      "2259                0.0  \n",
      "2260                1.0  \n",
      "2261                1.0  \n",
      "2262                0.0  \n",
      "2263                NaN  \n"
     ]
    }
   ],
   "source": [
    "# Add the column `Tomorrow Movement` by comparing the `Close Price` with the previous days as the training target\n",
    "\n",
    "train_df['Tomorrow Movement'] = np.where(train_df['Close Price'].diff() >= 0, 1, 0)\n",
    "test_df['Tomorrow Movement'] = np.where(test_df['Close Price'].diff() >= 0, 1, 0)\n",
    "\n",
    "train_df['Tomorrow Movement'] = train_df['Tomorrow Movement'].shift(-1)\n",
    "test_df['Tomorrow Movement'] = test_df['Tomorrow Movement'].shift(-1)\n",
    "\n",
    "print(train_df.head())\n",
    "print(train_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !--- You can add your own data preprocessing here ---!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 6)\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0      902.99       931.80      934.73     899.35  4048270080\n",
      "1      929.17       927.45      936.63     919.53  5413910016\n",
      "2      931.17       934.70      943.85     927.28  5392620032\n",
      "3      927.45       906.65      927.45     902.37  4704940032\n",
      "4      905.73       909.73      910.00     896.81  4991549952\n",
      "(2263,)\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n",
      "-----\n",
      "(251, 5)\n",
      "   Open Price  Close Price  High Price  Low Price      Volume\n",
      "0     2683.73      2695.81     2695.89    2682.36  1846463232\n",
      "1     2697.85      2713.06     2714.37    2697.77  2090595328\n",
      "2     2719.31      2723.99     2729.29    2719.07  2100767744\n",
      "3     2731.33      2743.15     2743.45    2727.92  1918869120\n",
      "4     2742.67      2747.71     2748.51    2737.60  1894823936\n",
      "(251,)\n",
      "0    1.0\n",
      "1    1.0\n",
      "2    1.0\n",
      "3    1.0\n",
      "4    1.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Divide x and y data\n",
    "\n",
    "train_x_df = train_df.drop(columns=['Tomorrow Movement'])\n",
    "train_y_df = train_df['Tomorrow Movement']\n",
    "\n",
    "test_x_df = test_df.drop(columns=['Tomorrow Movement'])\n",
    "test_y_df = test_df['Tomorrow Movement']\n",
    "\n",
    "print(train_x_df.shape)\n",
    "print(train_x_df.head())\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())\n",
    "print('-----')\n",
    "print(test_x_df.shape)\n",
    "print(test_x_df.head())\n",
    "print(test_y_df.shape)\n",
    "print(test_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Open Price  Close Price  High Price  Low Price    Volume\n",
      "0   -1.552572    -1.494607   -1.505683  -1.541181  0.813175\n",
      "1   -1.498571    -1.503581   -1.501760  -1.499581  1.823826\n",
      "2   -1.494446    -1.488625   -1.486853  -1.483605  1.808070\n",
      "3   -1.502119    -1.546489   -1.520714  -1.534956  1.299148\n",
      "4   -1.546921    -1.540136   -1.556744  -1.546417  1.511255\n",
      "0    0.0\n",
      "1    1.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "4    0.0\n",
      "Name: Tomorrow Movement, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize data\n",
    "\n",
    "# !--- Modify here if you want ---!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_x_df)\n",
    "\n",
    "normalized_train_x_df = scaler.transform(train_x_df)\n",
    "normalized_train_x_df = np.transpose(normalized_train_x_df)\n",
    "\n",
    "normalized_train_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_train_x_df[0],\n",
    "    'Close Price': normalized_train_x_df[1],\n",
    "    'High Price': normalized_train_x_df[2],\n",
    "    'Low Price': normalized_train_x_df[3],\n",
    "    'Volume': normalized_train_x_df[4],\n",
    "})\n",
    "\n",
    "normalized_test_x_df = scaler.transform(test_x_df)\n",
    "normalized_test_x_df = np.transpose(normalized_test_x_df)\n",
    "normalized_test_x_df = pd.DataFrame({\n",
    "    'Open Price': normalized_test_x_df[0],\n",
    "    'Close Price': normalized_test_x_df[1],\n",
    "    'High Price': normalized_test_x_df[2],\n",
    "    'Low Price': normalized_test_x_df[3],\n",
    "    'Volume': normalized_test_x_df[4],\n",
    "})\n",
    "\n",
    "print(normalized_train_x_df.head())\n",
    "print(train_y_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5475033141847105\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jaden\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict using Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr_model = LogisticRegression() # !--- Initialize the model here ---!\n",
    "lr_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "lr_training_acc = accuracy_score(train_y_df, lr_model.predict(normalized_train_x_df))\n",
    "print(lr_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "lr_predict_test_result = lr_model.predict(normalized_test_x_df)\n",
    "lr_testing_acc = accuracy_score(test_y_df, lr_predict_test_result)\n",
    "print(lr_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(lr_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.5137282196515144, 0.5258964143426295, 0.3694764768608263, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(1, 118, 1, 131)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, lr_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, lr_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing labels:\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Train & Predict with SVC\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC() # !--- Initialize the model here ---!\n",
    "svc_model.fit(normalized_train_x_df, train_y_df) # !-- Fill the training data here --!\n",
    "\n",
    "print('training accuracy:')\n",
    "# !-- Predict training target & print the training accuracy here --!\n",
    "svc_training_acc = accuracy_score(train_y_df, svc_model.predict(normalized_train_x_df))\n",
    "print(svc_training_acc)\n",
    "\n",
    "print('\\ntesting accuracy:')\n",
    "# !-- Predict testing target & print the testing accuracy here --!\n",
    "svc_predict_test_result = svc_model.predict(normalized_test_x_df)\n",
    "svc_testing_acc = accuracy_score(test_y_df, svc_predict_test_result)\n",
    "print(svc_testing_acc)\n",
    "\n",
    "print('\\npredicted testing labels:')\n",
    "print(svc_predict_test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision, recall, fbeta-score:\n",
      "(0.2765670386184346, 0.5258964143426295, 0.3624977895207681, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(0, 119, 0, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jaden\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('precision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df, svc_predict_test_result, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df, svc_predict_test_result).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2263, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  0  1\n",
      "2  1  0\n",
      "3  0  1\n",
      "4  1  0\n"
     ]
    }
   ],
   "source": [
    "# Define NN output groundtruth\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(train_y_df == 0, 1, 0)[:])\n",
    "train_y_df = pd.DataFrame(data=np.where(train_y_df == 0, 0, 1)[:])\n",
    "train_y_df = pd.concat( [ falling_prob, train_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "falling_prob = pd.DataFrame(data=np.where(test_y_df == 0, 1, 0)[:])\n",
    "test_y_df = pd.DataFrame(data=np.where(test_y_df == 0, 0, 1)[:])\n",
    "test_y_df = pd.concat( [ falling_prob, test_y_df ], axis=1, ignore_index=True )\n",
    "\n",
    "print(train_y_df.shape)\n",
    "print(train_y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 - loss:455.3646545410\n",
      "epoch:100 - loss:415.9311523438\n",
      "epoch:200 - loss:415.2249450684\n",
      "epoch:300 - loss:415.0151672363\n",
      "epoch:400 - loss:414.9302062988\n",
      "epoch:500 - loss:414.8922424316\n",
      "epoch:600 - loss:414.8739929199\n",
      "epoch:700 - loss:414.8632507324\n",
      "epoch:800 - loss:414.8550720215\n",
      "epoch:900 - loss:414.8473815918\n"
     ]
    }
   ],
   "source": [
    "# Define NN structure\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !--- You can modify the NN structure here ---!\n",
    "class M_NN(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(M_NN, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        acti_out = F.relu(h)\n",
    "        y_pred = self.linear2(h)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N = batch size, D_in = input size, H = hidden size, D_out = output size\n",
    "N, D_in, H, D_out = 300, 5, 100, 2  # !--- You can modify here ---!\n",
    "\n",
    "model = M_NN(D_in, H, D_out)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='sum') # !--- You can modify here ---!\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # !--- You can modify here ---!\n",
    "\n",
    "\n",
    "# Train NN\n",
    "# !--- You can modify here ---!\n",
    "\n",
    "for t in range(1000):\n",
    "    for batch_num in range(N, len(normalized_train_x_df), N): \n",
    "        y_pred = model(torch.FloatTensor(normalized_train_x_df[batch_num-N : batch_num].values.tolist())) # !-- Fill the training batch data here --!\n",
    "        loss = criterion(y_pred, torch.FloatTensor(train_y_df[batch_num-N : batch_num].values.tolist())) # !-- Fill the prediction & groundtruth here to calculate loss --!\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (t%100 == 0):\n",
    "        print('epoch:%d - loss:%.10f' % (t, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy:\n",
      "0.5483870967741935\n",
      "\n",
      "testing accuracy:\n",
      "0.5258964143426295\n",
      "\n",
      "predicted testing prob:\n",
      "tensor([[ 3.9665e-02, -3.8528e-02],\n",
      "        [ 5.6251e-02, -5.5031e-02],\n",
      "        [ 3.1222e-02, -2.7549e-02],\n",
      "        [ 5.0473e-02, -4.9862e-02],\n",
      "        [ 3.3700e-02, -3.2208e-02],\n",
      "        [ 2.1537e-02, -1.7915e-02],\n",
      "        [ 3.0546e-02, -2.9906e-02],\n",
      "        [ 6.4157e-02, -6.2916e-02],\n",
      "        [ 7.4161e-02, -7.3139e-02],\n",
      "        [-2.5638e-02,  2.6221e-02],\n",
      "        [ 8.5755e-02, -8.6848e-02],\n",
      "        [ 2.5381e-02, -2.2854e-02],\n",
      "        [ 6.4500e-02, -6.2928e-02],\n",
      "        [ 1.0345e-01, -1.0430e-01],\n",
      "        [ 5.5645e-02, -5.3243e-02],\n",
      "        [ 2.6138e-02, -2.6092e-02],\n",
      "        [ 2.8626e-02, -2.7276e-02],\n",
      "        [ 1.1743e-01, -1.1860e-01],\n",
      "        [ 7.9677e-03, -5.0600e-03],\n",
      "        [ 1.6075e-02, -1.3376e-02],\n",
      "        [ 2.7201e-02, -2.6363e-02],\n",
      "        [ 5.8053e-02, -5.4946e-02],\n",
      "        [-9.2915e-02,  9.2944e-02],\n",
      "        [-2.3686e-01,  2.3139e-01],\n",
      "        [ 2.5196e-01, -2.7088e-01],\n",
      "        [-1.1083e-02,  1.7050e-02],\n",
      "        [-2.8281e-01,  2.7851e-01],\n",
      "        [ 6.7559e-02, -8.9574e-02],\n",
      "        [ 5.9571e-02, -6.3199e-02],\n",
      "        [ 4.5569e-02, -4.7836e-02],\n",
      "        [ 1.3857e-01, -1.4481e-01],\n",
      "        [ 6.8310e-02, -7.6001e-02],\n",
      "        [ 2.9995e-02, -2.6088e-02],\n",
      "        [-5.4523e-03,  6.6696e-03],\n",
      "        [-4.5615e-02,  4.9832e-02],\n",
      "        [-9.1941e-03,  1.1927e-02],\n",
      "        [ 9.9037e-02, -1.0223e-01],\n",
      "        [ 8.7338e-02, -8.8814e-02],\n",
      "        [-7.5675e-02,  7.7588e-02],\n",
      "        [-8.8254e-02,  8.9810e-02],\n",
      "        [-8.7824e-02,  8.3773e-02],\n",
      "        [ 9.9019e-02, -1.0523e-01],\n",
      "        [ 1.2230e-01, -1.2777e-01],\n",
      "        [ 1.2976e-02, -1.4673e-02],\n",
      "        [ 6.0556e-02, -6.2517e-02],\n",
      "        [ 3.5020e-02, -3.5537e-02],\n",
      "        [ 1.1782e-01, -1.2101e-01],\n",
      "        [ 9.2344e-03, -6.3566e-03],\n",
      "        [-4.8741e-02,  4.9085e-02],\n",
      "        [-4.5367e-02,  4.6015e-02],\n",
      "        [-3.7686e-04,  2.5115e-03],\n",
      "        [ 5.4599e-02, -4.9065e-02],\n",
      "        [-6.2942e-02,  5.8317e-02],\n",
      "        [ 2.0534e-02, -1.7923e-02],\n",
      "        [ 1.1711e-03,  3.4983e-03],\n",
      "        [-1.2628e-01,  1.2613e-01],\n",
      "        [-1.6972e-01,  1.6881e-01],\n",
      "        [ 1.0920e-01, -1.1920e-01],\n",
      "        [-1.5489e-01,  1.4904e-01],\n",
      "        [-2.0775e-02,  2.1676e-02],\n",
      "        [ 6.8378e-02, -7.0281e-02],\n",
      "        [-1.5249e-01,  1.4259e-01],\n",
      "        [ 5.1387e-02, -5.7615e-02],\n",
      "        [ 1.5514e-01, -1.6729e-01],\n",
      "        [ 1.5201e-02, -1.4422e-02],\n",
      "        [-1.2699e-01,  1.2164e-01],\n",
      "        [-3.0553e-02,  3.5383e-02],\n",
      "        [ 5.0166e-02, -5.0264e-02],\n",
      "        [-1.4492e-02,  1.8278e-02],\n",
      "        [ 2.6312e-02, -2.3703e-02],\n",
      "        [-6.0405e-02,  5.8836e-02],\n",
      "        [ 2.2123e-02, -2.0905e-02],\n",
      "        [ 4.5411e-02, -4.3925e-02],\n",
      "        [ 8.6447e-03, -5.8119e-03],\n",
      "        [-8.5382e-03,  8.3540e-03],\n",
      "        [-5.1321e-02,  5.0520e-02],\n",
      "        [-1.3727e-02,  1.3435e-02],\n",
      "        [-1.2600e-01,  1.2038e-01],\n",
      "        [ 1.2157e-02, -1.6411e-02],\n",
      "        [ 4.9489e-02, -4.9297e-02],\n",
      "        [-8.8591e-03,  8.8965e-03],\n",
      "        [-7.1512e-02,  7.3989e-02],\n",
      "        [ 3.3322e-02, -3.7866e-02],\n",
      "        [-4.8755e-02,  5.0521e-02],\n",
      "        [ 6.6230e-03, -1.4047e-02],\n",
      "        [ 1.0612e-01, -1.1275e-01],\n",
      "        [ 9.7544e-03, -7.3493e-03],\n",
      "        [ 1.1203e-02, -1.2357e-02],\n",
      "        [ 6.2109e-02, -6.3204e-02],\n",
      "        [ 5.7785e-02, -5.7479e-02],\n",
      "        [ 2.4374e-02, -2.2881e-02],\n",
      "        [ 3.1142e-03, -3.7938e-04],\n",
      "        [-6.7146e-03,  6.9623e-03],\n",
      "        [ 3.6641e-02, -3.4426e-02],\n",
      "        [ 1.2844e-02, -1.0984e-02],\n",
      "        [ 2.3814e-03,  3.3736e-04],\n",
      "        [ 3.2554e-02, -2.9569e-02],\n",
      "        [-2.2257e-02,  2.4701e-02],\n",
      "        [ 6.9910e-02, -7.1211e-02],\n",
      "        [ 7.5886e-03, -1.0776e-02],\n",
      "        [ 2.9246e-03, -1.0790e-03],\n",
      "        [-3.0279e-02,  2.9031e-02],\n",
      "        [ 7.0655e-02, -7.0646e-02],\n",
      "        [-1.6791e-02,  1.8712e-02],\n",
      "        [ 5.8189e-02, -5.7158e-02],\n",
      "        [ 3.3320e-02, -3.0385e-02],\n",
      "        [ 2.1472e-02, -2.0178e-02],\n",
      "        [ 7.7379e-02, -7.8707e-02],\n",
      "        [ 1.4133e-02, -1.3435e-02],\n",
      "        [ 5.7202e-02, -5.6571e-02],\n",
      "        [ 2.8491e-02, -2.4129e-02],\n",
      "        [ 3.1442e-02, -2.9592e-02],\n",
      "        [ 2.4058e-04,  3.2333e-03],\n",
      "        [ 2.9352e-02, -2.6664e-02],\n",
      "        [ 6.2929e-02, -6.3334e-02],\n",
      "        [ 4.6705e-02, -4.7048e-02],\n",
      "        [ 5.3679e-02, -5.4476e-02],\n",
      "        [ 2.1274e-02, -1.7897e-02],\n",
      "        [-3.0325e-02,  3.1152e-02],\n",
      "        [ 2.4680e-02, -2.0720e-02],\n",
      "        [-5.1323e-02,  4.7036e-02],\n",
      "        [ 2.1023e-02, -1.8514e-02],\n",
      "        [-6.9003e-02,  7.1829e-02],\n",
      "        [ 5.9537e-02, -6.0885e-02],\n",
      "        [-8.3722e-03,  1.2866e-02],\n",
      "        [ 6.7346e-02, -6.9981e-02],\n",
      "        [-6.1271e-02,  6.2577e-02],\n",
      "        [ 4.4701e-02, -4.6087e-02],\n",
      "        [ 6.9456e-02, -7.1420e-02],\n",
      "        [ 6.4078e-02, -6.3176e-02],\n",
      "        [ 3.8868e-02, -3.6505e-02],\n",
      "        [ 6.0527e-03, -3.1073e-03],\n",
      "        [ 6.8045e-02, -6.7471e-02],\n",
      "        [ 3.8625e-02, -3.6984e-02],\n",
      "        [ 1.9452e-02, -1.7093e-02],\n",
      "        [ 8.1924e-02, -8.1688e-02],\n",
      "        [ 4.5934e-02, -4.4290e-02],\n",
      "        [ 2.2468e-02, -1.9862e-02],\n",
      "        [ 2.6220e-02, -2.2301e-02],\n",
      "        [ 5.0672e-02, -4.9350e-02],\n",
      "        [ 3.7413e-02, -3.5626e-02],\n",
      "        [ 1.1967e-01, -1.2091e-01],\n",
      "        [ 5.2999e-02, -4.8195e-02],\n",
      "        [-2.5576e-02,  2.4448e-02],\n",
      "        [-1.1832e-02,  1.3455e-02],\n",
      "        [ 5.8739e-02, -5.5524e-02],\n",
      "        [ 1.6185e-02, -1.4685e-02],\n",
      "        [ 1.0548e-01, -1.0806e-01],\n",
      "        [ 6.5221e-02, -6.3936e-02],\n",
      "        [ 6.2683e-02, -6.1913e-02],\n",
      "        [ 4.5665e-02, -4.1567e-02],\n",
      "        [ 3.8485e-02, -3.5483e-02],\n",
      "        [ 2.6526e-02, -2.2817e-02],\n",
      "        [ 1.7390e-02, -1.6116e-02],\n",
      "        [-7.1961e-03,  1.0028e-02],\n",
      "        [ 6.4829e-02, -6.3432e-02],\n",
      "        [ 1.2972e-02, -1.4879e-02],\n",
      "        [ 6.1322e-02, -5.8293e-02],\n",
      "        [ 6.9082e-02, -6.8528e-02],\n",
      "        [ 4.5257e-02, -4.2674e-02],\n",
      "        [ 4.4143e-02, -3.9521e-02],\n",
      "        [ 3.8129e-02, -3.5520e-02],\n",
      "        [ 2.4130e-02, -2.0811e-02],\n",
      "        [ 6.9668e-02, -6.8034e-02],\n",
      "        [ 7.8500e-02, -7.6583e-02],\n",
      "        [ 3.3310e-02, -3.0673e-02],\n",
      "        [ 8.2354e-02, -8.1555e-02],\n",
      "        [ 2.4606e-02, -2.2845e-02],\n",
      "        [ 5.6100e-02, -5.4452e-02],\n",
      "        [ 4.9066e-02, -4.8540e-02],\n",
      "        [ 4.3862e-02, -4.3503e-02],\n",
      "        [ 1.7159e-02, -1.7219e-02],\n",
      "        [ 5.0316e-02, -4.7415e-02],\n",
      "        [ 2.8304e-02, -2.4502e-02],\n",
      "        [ 8.5798e-02, -8.6379e-02],\n",
      "        [ 5.0194e-02, -4.8722e-02],\n",
      "        [ 7.1298e-02, -6.8333e-02],\n",
      "        [ 4.4832e-02, -4.3731e-02],\n",
      "        [ 2.2456e-03, -1.2544e-04],\n",
      "        [ 8.3496e-02, -8.1675e-02],\n",
      "        [ 5.4880e-02, -5.1412e-02],\n",
      "        [ 8.8313e-02, -8.5761e-02],\n",
      "        [ 7.7420e-02, -7.2647e-02],\n",
      "        [ 5.1379e-02, -4.9223e-02],\n",
      "        [ 3.8255e-02, -3.4745e-02],\n",
      "        [ 2.0495e-02, -1.7025e-02],\n",
      "        [ 5.4750e-02, -5.0920e-02],\n",
      "        [ 6.6667e-02, -6.3373e-02],\n",
      "        [ 5.2603e-02, -4.9855e-02],\n",
      "        [ 5.4808e-02, -5.1264e-02],\n",
      "        [ 3.8876e-02, -3.5835e-02],\n",
      "        [ 4.5664e-03, -7.7842e-03],\n",
      "        [ 5.5872e-04, -2.9044e-03],\n",
      "        [ 6.5228e-02, -6.7418e-02],\n",
      "        [ 4.2117e-02, -3.9158e-02],\n",
      "        [-2.0487e-01,  2.0178e-01],\n",
      "        [-1.0094e-01,  9.6494e-02],\n",
      "        [ 2.5997e-02, -3.4641e-02],\n",
      "        [-1.8079e-02,  2.1319e-02],\n",
      "        [ 1.4390e-01, -1.4844e-01],\n",
      "        [ 2.6706e-02, -3.1931e-02],\n",
      "        [-6.3596e-02,  6.0627e-02],\n",
      "        [ 4.8063e-03, -2.3147e-03],\n",
      "        [-2.6642e-02,  2.7407e-02],\n",
      "        [ 8.0206e-02, -8.9416e-02],\n",
      "        [-2.1000e-01,  2.0650e-01],\n",
      "        [ 1.0234e-01, -1.0560e-01],\n",
      "        [-6.6597e-03,  1.3777e-03],\n",
      "        [-1.0932e-01,  9.8295e-02],\n",
      "        [ 1.4072e-01, -1.4620e-01],\n",
      "        [ 4.7230e-02, -4.1978e-02],\n",
      "        [ 9.1948e-02, -9.4996e-02],\n",
      "        [-3.4794e-02,  3.0239e-02],\n",
      "        [ 5.1087e-02, -5.1883e-02],\n",
      "        [ 6.6141e-02, -6.5825e-02],\n",
      "        [ 1.4231e-01, -1.4608e-01],\n",
      "        [ 3.6334e-02, -3.5488e-02],\n",
      "        [ 1.1961e-03, -3.5646e-03],\n",
      "        [-1.1158e-01,  1.1055e-01],\n",
      "        [-4.6341e-03,  7.3275e-03],\n",
      "        [-8.2000e-02,  7.8338e-02],\n",
      "        [ 1.2173e-01, -1.3265e-01],\n",
      "        [ 7.3809e-02, -7.4512e-02],\n",
      "        [-9.5461e-02,  9.3216e-02],\n",
      "        [-2.3172e-02,  2.4002e-02],\n",
      "        [-2.4303e-02,  2.8494e-02],\n",
      "        [-3.0332e-02,  3.3880e-02],\n",
      "        [ 6.9189e-02, -6.9792e-02],\n",
      "        [ 5.6714e-02, -5.9111e-02],\n",
      "        [ 1.6047e-01, -1.6959e-01],\n",
      "        [ 1.7702e-02, -1.7642e-02],\n",
      "        [ 1.0058e-01, -1.0202e-01],\n",
      "        [ 4.0920e-02, -4.1541e-02],\n",
      "        [-2.0476e-01,  2.0159e-01],\n",
      "        [-2.0377e-01,  2.0063e-01],\n",
      "        [ 1.1657e-01, -1.3332e-01],\n",
      "        [-1.6226e-01,  1.5905e-01],\n",
      "        [ 2.1948e-02, -3.5359e-02],\n",
      "        [-7.7060e-02,  7.4030e-02],\n",
      "        [-1.8553e-02,  2.3611e-02],\n",
      "        [-1.8811e-02,  1.8420e-02],\n",
      "        [-8.4783e-02,  8.4779e-02],\n",
      "        [-1.3499e-01,  1.3073e-01],\n",
      "        [-4.9392e-02,  4.7289e-02],\n",
      "        [-1.2709e-01,  1.2415e-01],\n",
      "        [-9.2963e-02,  8.6784e-02],\n",
      "        [-1.4115e-01,  1.4199e-01],\n",
      "        [-2.1187e-01,  2.1149e-01],\n",
      "        [ 2.3898e-01, -2.6298e-01],\n",
      "        [ 9.1161e-02, -1.1278e-01],\n",
      "        [-7.4209e-02,  7.3667e-02]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "predicted testing labels:\n",
      "[1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1\n",
      " 0 0 0 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1\n",
      " 1 0 0 0 0 1 1 1 1 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "nn_predict_train_y = model(torch.FloatTensor(normalized_train_x_df.values.tolist()))# !-- Predict training data here --!\n",
    "result_train = np.where(nn_predict_train_y[:, 0] > nn_predict_train_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('training accuracy:')\n",
    "print(accuracy_score(train_y_df[0], result_train))\n",
    "\n",
    "nn_predict_test_y = model(torch.FloatTensor(normalized_test_x_df.values.tolist())) # !-- Predict training data here --!\n",
    "result_test = np.where(nn_predict_test_y[:, 0] > nn_predict_test_y[:, 1], 1, 0) # !-- You can modify here --!\n",
    "print('\\ntesting accuracy:')\n",
    "print(accuracy_score(test_y_df[0], result_test))\n",
    "\n",
    "print('\\npredicted testing prob:')\n",
    "print(nn_predict_test_y)\n",
    "print('\\npredicted testing labels:')\n",
    "print(result_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "precision, recall, fbeta-score:\n",
      "(0.5455776892430279, 0.5258964143426295, 0.5064245107509046, None)\n",
      "\n",
      "confusion matrix(tn, fp, fn, tp):\n",
      "(44, 88, 31, 88)\n"
     ]
    }
   ],
   "source": [
    "# Print precision, recall, fbeta-score and confusion matrix\n",
    "\n",
    "print('\\nprecision, recall, fbeta-score:')\n",
    "print(precision_recall_fscore_support(test_y_df[0], result_test, average='weighted'))\n",
    "print('\\nconfusion matrix(tn, fp, fn, tp):')\n",
    "tn, fp, fn, tp = confusion_matrix(test_y_df[0], result_test).ravel()\n",
    "print((tn, fp, fn, tp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "在三種方法中(Logistic regression、SVM、Neural network)，發現NN所預測出來的表現最好。但礙於本身先備能力不足與時間緊迫，我未能很有效的提升每個model的準確率。未來有機會會繼續嘗試，可行的approach會像是：<br>\n",
    "1.想辦法更了解每個model中參數的意義，以方便調整合適於資料屬性的參數<br>\n",
    "2.查找一些與股票預測相關的指數或方法等等，利用增加新的feature去提升預測準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
